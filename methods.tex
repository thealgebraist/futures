\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}

\title{Mathematical Methods for Futures Prediction: Comparative Analysis}
\author{Gemini CLI Agent}
\date{February 18, 2026}

\begin{document}

\maketitle

\section{Stochastic Models}
\subsection{Merton Jump-Diffusion}
The price process $S_t$ is modeled as a stochastic differential equation (SDE):
\[ \frac{dS_t}{S_t} = \mu dt + \sigma dW_t + d\left( \sum_{i=1}^{N_t} (Y_i - 1) \right) \]
where $W_t$ is a Wiener process, $N_t$ is a Poisson process with intensity $\lambda$, and $Y_i$ is the jump size.

\section{Neural Architectures}
\subsection{Neural Ordinary Differential Equations (Neural ODE)}
Depth is treated as a continuous variable $t$:
\[ \frac{dh(t)}{dt} = f(h(t), t, \theta) \]
Solved via Euler discretization: $h_{t+1} = h_t + f(h_t, t, \theta)\Delta t$.

\subsection{Liquid Time-Constant (LTC) Networks}
Dynamical systems with input-dependent time constants $\tau(x, t)$:
\[ \frac{dh}{dt} = - \left[ \frac{1}{\tau} + f(x, t) \right] h + f(x, t) A \]

\subsection{Discontinuous Piecewise Linear (PWL) Models}
Jump linear regression allowing vertical and derivative discontinuities at knots $c_i$:
\[ y = \beta_0 + \beta_1 x + \sum_{i=1}^N \left[ \gamma_{0,i} \mathbb{I}(x > c_i) + \gamma_{1,i} (x-c_i) \mathbb{I}(x > c_i) \right] \]

\section{Benchmarking and Optimization}
\subsection{R-Adam and Gradient Clipping}
To stabilize training on non-stationary financial data, we employ Rectified Adam and global norm clipping:
\[ \mathbf{g}_{clip} = \mathbf{g} \cdot \min\left(1, \frac{\tau}{\|\mathbf{g}\|_2}\right) \]

\section{Results and Summary}
\subsection{Jump-Linear Benchmark (64-dim Input, 16-dim Output)}
The Discontinuous PWL-FFNN was benchmarked for 60s per configuration.
\begin{center}
\begin{tabular}{lrr}
\toprule
Jump Points ($N$) & Best Training MSE & Throughput (Steps) \\
\midrule
1 & 0.0596 & 6,214,334 \\
8 & 0.0588 & 2,816,079 \\
128 & \textbf{0.0581} & 593,689 \\
512 & 0.0630 & 162,430 \\
\bottomrule
\end{tabular}
\end{center}
The $N=128$ configuration achieved the best balance between complexity and convergence within the 60s window.

\subsection{Monte Carlo Simulation (Merton Jump-Diffusion)}
The SDE model executed 97,504 simulation batches in 60s. The predicted mean price for the target future after 4 intervals (40 mins) was 6,881.83.

\section{Conclusion}
Differential and discontinuous models offer high-resolution mapping of futures data. The C++23 Accelerate implementation allows for millions of iterations, making these "jump" models viable for real-time high-frequency forecasting.

\end{document}
